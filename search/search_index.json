{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FSO website documentation","text":"<p>The FSO Website implements the methods described in these papers: </p> <ul> <li>Improving algorithms for fantasy basketball</li> <li>Dynamic algorithms for fantasy basketball</li> <li>Optimizing for Rotisserie fantasy basketball</li> </ul> <p>The methods are designed for category leagues (not points leagues). </p> <p>Broadly, the papers formulate fantasy basketball as a math problem, and provide methods for selecting players based on that formulation. The methods take projections of player performance as an input. They also invoke many simplifications, which are handy both because real fantasy basketball is extremely complex, and because perfect mathematical solutions are not always easy. Because of the reliance on existing projections and the simplifications invoked, these methods should in no way be considered the end-all-be-all or truly \"optimal\" in any sense. They are just one potential starting point. </p> <p>The website is mostly designed for drafts and auctions. It also provides some related analyses for leagues that are already underway via 'Season Mode'.</p> <p>Source code here</p>"},{"location":"auctions/","title":"Auctions","text":"<p>Auction drafting is more complicated than snake drafting because auction drafters need to decide how much to bid on players, not just which players to take. This level of complexity makes strategizing perfectly for an auction even more impossible than it is for a snake draft. </p> <p>Still, quantitative analysis can be helpful in the auction context. In particular, it can be used to benchmark player values in terms of auction dollars. </p> <p>The auction mode of this website implements some basic methods for converting G-scores and H-scores into dollar values. It also makes an adjustment to player values that is unique to the auction context called SAVOR.</p>"},{"location":"auctions/#using-auction-mode","title":"Using auction mode","text":"<p>When the selected mode is 'auction', the website will provide analysis for either synthetic or live auctions. </p>"},{"location":"auctions/#manual-entry","title":"Manual entry","text":"<p>Player selection information can be entered into the editable table. Analysis will not begin until the 'Lock in' button is pressed; this is to allow for multiple updates without running H-scoring every time. </p>"},{"location":"auctions/#live-connection","title":"Live connection","text":"<p>For some reason, Yahoo's API does not return anything for auctions until a few minutes after the auction has started. Because of that, the displayed values may be the default values for the first few picks. </p> <p></p> <p>Once the 'Auction has not yet begun' message is gone, information is being received from Yahoo. </p>"},{"location":"auctions/#quantifying-auction-value","title":"Quantifying auction value","text":"<p>A well-known heuristic for quantifying auction value is described in many places including this article from rotowire. For reference, it is</p> <ol> <li>Calculate the replacement-level score. That is, if 156 players will be chosen, the 157th-highest score is the replacement value</li> <li>Adjust all scores by subtracting out the replacement-level value. If this would make a score go below zero, set it to zero instead</li> <li>Calculate the sum of scores above replacement. This is the total amount of real value available in the auction</li> <li>Divide the total number of dollars available by the total amount of real value available. This yields a conversion rate from score above replacement to dollars</li> <li>Multiply each players' score above replacement with the conversion rate calculated in the previous step. The result is each players' auction value</li> </ol> <p>This process ensures both that players' dollar values proportional to their values over replacement, and that the total of all players' dollar values are equal to the total amount of $ available. </p> <p>Auction mode uses this process to quantify player value in a few ways.</p>"},{"location":"auctions/#converting-g-score-value-to-dollar-value","title":"Converting G-score value to dollar value","text":"<p>Two kinds of dollar values are presented for G-scores</p> <p></p> <p>G-score-based $ values in a synthetic draft context</p> <p>'Orig. $' value, or original value, is the same as the auction value heuristic described above. Original values do not change during auctions, and can be helpful as objective benchmarks that quantify how good deals are in the abstract. </p> <p>'Gnrc. $' value, or generic value, is a variant which is recomputed as players are taken and the amount of available money decreases. For example if two players out of 156 have been taken for $200 total, those two players are removed from the list, the replacement-level value becomes the 155th-highest score, and 200 dollars are removed from the amount of total dollars available. The same process as for original value is then applied using the modified inputs. Generic value may be useful strategically because it reflects whether other managers have been under- or over-spending. E.g. if managers have been underspending, it implicitly takes into account the fact that some managers have excess money and will be able to pay more for remaining players. </p>"},{"location":"auctions/#converting-h-score-value-to-dollar-value","title":"Converting H-score value to dollar value","text":"<p>H-scores are probabilities, not general values. They are converted into dollar values with two steps</p> <ol> <li>It is estimated how much money it would take to improve winning chances by the same amount as taking the player</li> <li>Those monetary estimates are refined into dollar values with the auction value heuristic as described previously</li> </ol> <p></p> <p>H-score-based $ values in a synthetic draft context</p> <p>The original and generic values are based on players' H-scores converted to monetary estimates for the first pick of the auction, with no players taken and no cash spent. Those are not context-dependent so they stay the same for the whole auction. </p> <p>Like for G-scores, the original values are processed once with the auction value heuristic and stay the same throughout the auction. </p> <p>For generic values, the underlying step 1 estimates are not changed, but the step 2 process is adjusted for the number of players remaining etc. That is, if a player was estimated to be worth $30 originally, that number will continue to be plugged in as a value to the auction value heuristic process. The auction value heuristic process will be slightly different because players have been taken and cash has been spent. </p> <p>H-scoring is also run with with the updated context for the drafter in question. Those monetary estimates become 'Your $' after refinement through the auction value heuristic. The difference between 'Your $' and 'Gnrc. $' highlights players which are more or less valuable to the drafter in question than they are to a generic drafter. </p>"},{"location":"auctions/#the-savor-adjustment","title":"The SAVOR adjustment","text":"<p>After the previously described processing for H-score and G-score dollar values, the website makes an additional adjustment called SAVOR. It is reflected in all of the displayed dollar values. </p> <p>SAVOR stands for Streaming-Adjusted Value Over Replacement. It adjusts for the fact that the lowest-ranking players are highly likely to be shuffled around over the course of the season through waiver wires and free agency, so it is not worth spending much money on them, even if theoretically they are projected to be somewhat more valuable than their alternatives. This is a known concept in the fantasy basketball community- for example it is referenced in this reddit thread.</p> <p>Details of the mathematical model behind the SAVOR adjustment are included in the appendix of an old version of the first paper. It was removed from the most recent version because it was not topical. </p> <p></p> <p>SAVOR takes an input parameter, \\(S_{\\sigma}\\). It controls the degree to which players are expected to move up and down across the season according to the SAVOR model. Its default value is sourced by vibes- different values may be just as or more reasonable. </p>"},{"location":"drafts/","title":"Drafts","text":"<p>H-scores and G-scores are designed directly for drafts, so they can be applied to drafts without modification.</p>"},{"location":"drafts/#using-draft-mode","title":"Using draft mode","text":""},{"location":"drafts/#manual-entry","title":"Manual entry","text":"<p>With manual entry, draft picks are entered through the website. </p> <p></p> <p>The 'Lock in selection' button puts the player shown in the dropdown into the next draft slot. Picks go in a snake order and cannot be skipped. </p> <p>The default order in which players are listed in the dropdown is by total G-score. The top player on the list is the default selection. So if 'Lock in selection' is pressed multiple times in succession, available players are taken in G-score order. </p> <p>The table below the player selection dropdown shows which players have been taken by which drafters. </p> <p>Tables for G-scores and H-scores of candidate players are shown when the 'Run algorithm' button on the right is pressed. </p> <p></p> <p>The G-score table is available immediately because it is static; the H-scoring table will take some time to fully update. The H-score details tab will also be available, synched to the current display of the H-score table and updated as the algorithm runs. </p> <p></p>"},{"location":"drafts/#live-connection","title":"Live connection","text":"<p>With a live connection, draft selections are provided by the platform. The entire screen becomes a view for candidate evaluation. </p> <p></p> <p>The 'Refresh Analysis' button fetches new information on draft picks from the platform and re-runs H-scoring. </p>"},{"location":"gscores/","title":"G-scores","text":"<p>It is well-understood that player value in category leagues is dependent on context. No single number, independent of circumstances around team, opposition, etc. can ever fully define a player's value. However, that has not stopped fantasy enthusiasts from designing and applying so-called 'static' ranking systems. Despite their limitations in theory, they are useful in practice because they are simple and convenient. One ought not let the perfect get in the way of the good. </p> <p>The website uses G-scores as a measure of static value. G-scores are a variant of the traditional Z-score metric, as described in the first paper. Briefly, they extend Z-scores, which account for player-to-player variance, to account for variance in player performances as well. G-scores can be shown to be approximately optimal for the contrived case of all other players being chosen randomly, which is as reasonable an assumption as any when context cannot be taken into account. They down-weights volatile categories like steals and turnovers relative to Z-scores. </p> <p>While limited in terms of flexibility, G-scores may be helpful for understanding a player's strength and weaknesses, seeing how they relate to other players, and ballparking their overall value. </p>"},{"location":"gscores/#g-score-table","title":"G-score table","text":"<p>During auctions and drafts, a tab will be available with the G-score table for available players. The G-score table shows available players ordered by total G-score during drafts and auctions. It includes the categorical components of G-scores as well.</p>"},{"location":"gscores/#team-table","title":"Team table","text":"<p>The team table shows the G-scores of players already chosen for a team, and their totals. The totals show how the team is doing in general, though one should keep in mind that non-turnover categories tend to have high values during early rounds because only the strongest players are being taken. </p>"},{"location":"gscores/#calculation","title":"Calculation","text":"<p>The coefficients for G-scores used by the website were calculated based on real historical data, as shown in the paper. One should not that real week-to-week variance in historical data is not necessarily the same thing as forecasted variance for future weeks, so the week-to-week variance factor may be too strong or too weak in practice. </p>"},{"location":"hscores/","title":"H-scores","text":"<p>H-scoring is a framework introduced in the second paper for dynamic player selection. In short, for each candidate player, it optimizes for future draft pick strategy in terms of category weightings and position allocations, and estimates performance based on those strategies. Because of its ability to adapt to drafting circumstances, H-scoring arguably offers a more compelling and logical starting point for draft strategy than G-scoring.</p> <p>The website includes a module which performs the H-score algorithm programatically. </p>"},{"location":"hscores/#parameter-inputs","title":"Parameter inputs","text":"<p>The H-scoring algorithm has a few input parameters which are configurable by the user. </p>"},{"location":"hscores/#punting-parameters","title":"Punting parameters","text":"<p>The punting parameters, available through Algorithm Parameters</p> <p>These two parameters control how the H-scoring algorithm thinks about the landscape of player statistics that it will have to choose from in the future. Roughly, when \u03c9 is high, the algorithm punts more. The default values were configured based on what worked well in testing. </p>"},{"location":"hscores/#number-of-iterations","title":"Number of iterations","text":"<p>The number of iterations parameter, available through Algorithm Parameters </p> <p>The H-scoring algorithm runs for the specified number of iterations. Additional iterations increase the precision of H-scoring, at the cost of longer computation. In practice thirty iterations, the default, works reasonably well.  </p> <p>When the website runs H-scoring, it shows the current results after the first iteration, once every fifteen iterations after that, and after the last iteration. </p>"},{"location":"hscores/#h-score-table","title":"H-score table","text":"<p>The H-score table for candidate evaluation lists players in order of their H-score rank, along with category-level detail. </p> <p></p> <p>Top Each Category H-scores for the first pick, 2024-25 season</p>"},{"location":"hscores/#category-level-h-scores","title":"Category-level H-scores","text":"<p>Category-level H-scores are an in important part of the H-scoring process. Unlike with G-scores, they are not direct reflections of the candidate player's characteristics. Instead, they show what the H-scoring algorithm expects the average win rate against all opponents will be, assuming the candidate player is taken. H-scoring calculates that expectation based on not just the characteristics of the candidate player, but also on previously chosen players and potential future picks. The statistics of future picks are estimated based on H-scoring's preferred strategy for future picks.</p> <p>Because other factors are taken into account, the categorical strengths and weaknesses presented in the H-score table are often quite different from those of the candidate players. For early picks, the most important factor is the strategy for future draft picks. For example, Shai Gilgeous-Alexander's row above for the first pick in the draft shows a very low probability of winning the Rebound category, despite SGA being a decent rebounder himself. This is because H-scoring's preferred strategy with SGA involves deprioritizing rebounds with future picks.</p> <p>In later draft rounds, the importance of previously chosen players increases and the importance of the strategy for future picks decreases. Also, the strategy for future picks tends to become more stable across players, since the direction of the team is already decided. So categorical H-scores tend to become consistent across players. </p> <p></p> <p>Top H-scores for a round seven pick in a mock draft, with relatively stable scores across categories. Each Categories, 2024-25</p>"},{"location":"hscores/#overall-h-scores","title":"Overall H-scores","text":"<p>The overall H-score is both the metric that H-scoring is trying to optimize with its future draft pick strategy, and the one used to rank players. It is based on the category-level H-scores. For Each Categories scoring, it is defined as the average expected win rate across categories.</p> <p>Using the overall H-score to rank players incorporates the strategic concept that player value is dependant on 'build'. For example, Giannis Antetokounmpo typically is rated poorly according to quantitative metrics, because he is dragged down by poor Free Throw shooting. H-scoring sees that it can build a team around him that leans into his strengths, by punting the Free Throw category and prioritizing others. He therefore ends up ranked significantly higher by H-score than he would by pure G-score. </p>"},{"location":"hscores/#most-categories-scoring","title":"Most Categories scoring","text":"<p>For Most Categories, the average expected win rate is a poor proxy for success. A team that wins five out of nine categories 100% of the time and always loses the others is better for that format than one that wins each category 60% of the time, despite having a lower average expected win rate (56% vs 60%). For that reason, switching the format to Most Categories switches the definition of the overall H-score to the probability of winning a majority of categories (assuming they are independent for the sake of making the calculation less intensive).</p> <p></p> <p>Top Most Category H-scores for the first pick, 2024-25 season</p> <p>The table above is based on the same dataset as the Each Category version. The numbers, and the order of players, are different because they use the Most Categories objective instead of the Each Category objective. With Most Categories scoring, the algorithm is even more incentivized to punt, and tends to do so to a more extreme degree. Players that benefit strongly from punting like Giannis also end up ranking better (third instead of fifth).</p>"},{"location":"hscores/#h-score-details-tab","title":"H-score details tab","text":"<p>The main H-score table gives only indirect insight into the strategies that H-scoring wants to use with each candidate player. The H-score details tab explains the strategy for individual players more directly. It is broken down into two parts: expectations, and future strategy.</p>"},{"location":"hscores/#expectations","title":"Expectations","text":"<p>Expectations for a team with Giannis as the first pick based on Dyson Daniels as the second, Each Category 2024-25</p> <p>The first row is the same as that from the main H-scoring table, included for convenience. </p> <p>The table below breaks down the components of the team, in terms of G-scores vs. the average of other teams. 'Current diff' represents the G-score differential for the draft so far, including players already drafted in the current round and excluding the candidate player. Teams that have not made their pick for the round are filled in with an estimate of the statistics of their next player. So in this case above, 'Current diff' represents other teams' first two picks vs. Giannis, with estimates for other teams that have only drafted one player. 'Future player diff' is the expected difference between future picks made by the drafter and those made by other teams, based on the strategy adopted by H-scoring. In this case the G-score for Free Throws is heavily negative because the algorithm wants to punt it with future picks. 'Current diff' plus the candidate player plus 'Future player diff' equals the total differential versus other teams, which H-scoring uses to calculate win probabilities.  </p> <p>The ranks show how the candidate player ranks as a pick in this situation, both by H-score and G-score. This can also be seen through the H-score or G-score main tables, and is included here as a convenience. </p>"},{"location":"hscores/#future-strategy","title":"Future strategy","text":"<p>The future strategy tab shows H-scoring's strategy for future picks.</p> <p></p> <p>Strategies for future draft picks based on having Giannis and Dyson Daniels already, Each Category 2024-25</p> <p>The category weightings displayed in the first row are based on H-scoring's internal model of how drafting works. It assumes that the drafter will use those weights exactly for candidates going forward, and it also assumes that those weights will have a certain influence on the aggregate statistics of future picks (details are in the paper). One might note that in the case above, the weight for Free Throws is surprisingly high, despite the obvious fact that the algorithm is deprioritizing the category heavily. The reason for this is that in general, H-scoring does not think it needs to adjust weights all that much in order to skew the available candidates to the categories it wants (again, details are in the paper). </p> <p>The flex position allocations show how the algorithm expects to use its flex spots, which can take players of multiple positions. This is relevant because the algorithm understands that different positions have different statistical tendencies. In the example above, the algorithm is leaning heavily on taking Power Forwards and Centers with its flex spots, likely because they tend to have poor Free Throw rates, and that synergizes with the strategy of punting Free Throws. </p> <p>The algorithm also has some leeway in how it arranges players already taken in terms of position, freeing up different positions to take with future draft picks. The roster assignment row shows what the algorithm is thinking in this regard. In the example above, it is choosing to categorize Daniels as a SF, likely because it does not want to take more SFs in general. </p>"},{"location":"hscores/#h-scoring-tendencies","title":"H-scoring tendencies","text":"<p>The H-scoring algorithm does not take explicit instructions on overall strategy. However, it \"learns\" some general strategy based on its understanding of the problem </p> <p></p> <p>Image from the paper</p> <p>This image from the paper shows how the H-scoring algorithm generally performs on a category level. It shows that H-scoring often punts categories, though the punts are not always total. It often preserves some chance of winning punted categories. For the categories it does not punt, it tries to be highly competitive in them without going overboard, which may be a wasteful allocation of resources. </p>"},{"location":"hscores/#limitations","title":"Limitations","text":"<p>H-scoring has numerous limitations. Some of the most major are </p> <ul> <li>H-scoring is reliant on a single set of projections which may differ from the beliefs of other managers. Assuming its projections are correct, the algorithm can become overconfident and assess its own team as being so strong that the only way to improve it is to \"un-punt\" a category. This can lead to late round picks which run counter to the build of a team. The website does have a way to mitigate this, to a degree- see the page on the Bayesian strength adjustment</li> <li>The optimization process for H-scoring only considers one strategy profile. It does not consider how robust players are to different strategy profiles, which may be relevant because circumstances can change during a draft, and the algorithm might switch strategies drastically. </li> <li>The internal logic of H-scoring does not understand that other drafters may also be trying to punt categories. This will lead to inaccurate projections of other teams, and therefore inaccurate projections of expected win rates</li> <li>H-scoring does not model category variance based on players. Instead, it assumes that week-to-week variance is the same for all matchups. This is not always accurate, especially when a team is punting a category</li> <li>H-scoring's model for what sorts of players will be available in the future is simplified, and may fail to properly account for individual players with exceptional profiles</li> <li>H-scoring does not take into account the effect of streaming players, trading, etc. These all may add additional strategic considerations </li> </ul>"},{"location":"parameters/","title":"Parameters","text":"<p>Various calculations performed by the website take in parameters that are configurable by the user. They dictate how injury risk is handled, how aggressively the algorithm will punt, and more. </p>"},{"location":"parameters/#player-stat-parameters","title":"Player stat parameters","text":""},{"location":"parameters/#injury-handling","title":"Injury handling","text":"<p>Projections generally include forecasts of how many games each player will play during the season, but incorporating them into player valuations is not entirely straightforward. </p> <p>Typically, player valuations are presented in two ways: per-game values and season total values. Per-game values exclude the missing games, while season total values include them as all zeros. The website allows granular control of the spectrum between those two perspectives, plus an additional correction for players being substituted out for replacement players. </p> <p></p> <p>The first factor, \u03c5, scales injury rates on a spectrum between per-game value and season total values. For example if \u03c5 is 0.4 and a player is expected to be injured 10% of the time, that injury rate is adjusted to 4%, and the player's volume projections are multiplied by 96%. A \u03c5 of 0 is equivalent to per-game totals, and a \u03c5 of 1 is equivalent to season total projections. The argument for setting \u03c5 to 1 is that the correct expected value of real player production fully accounts for the probability of injury. The counter-argument is that teams need to be somewhat lucky to have any shot at competing for a championship, so it makes sense for them to strategize with the assumption that their injury luck is reasonably good. The default value for \u03c5 is 1, equivalent to season total values.</p> <p>The second factor, \u03c8, controls an adjustment for replacement players. It is assumed that when a player misses a game, they will be replaced by a replacement-level player for that game \u03c8 of the time, and that is incorporated into projections after they have been adjusted for injury rates. A replacement-level player has the total G-score value of the Nth-highest player, spread across categories, where N is the number of players in the league.  So continuing the previous example, if \u03c8 is 0.75, then 3% times a replacement player's value is added to the player's projection. The right value for \u03c8 depends on a league's IR rules and how active managers will be in replacing their injured player. It defaults to 0.8.</p>"},{"location":"parameters/#chi-factor","title":"Chi factor","text":"<p>For Rotisserie leagues, an additional parameter called \u03c7 is required.</p> <p></p> <p>\u03c7 controls the estimate of uncertainty in pre-season projections. See the relevant section on Rotisserie for more detail. </p>"},{"location":"parameters/#auction-noise","title":"Auction noise","text":"<p>For auction drafts, an additional parameter called \\(S_\\sigma\\) is required.</p> <p></p> <p>\\(S_\\sigma\\) quantifies the standard deviation of dollar values for players throughout a season, which is important for the SAVOR adjustment. Roughly speaking it controls the degree to which low-level players are down-weighted for potentially beocoming irrelevant. </p>"},{"location":"parameters/#bayesian-strength-adjustment","title":"Bayesian strength adjustment","text":"<p>The \\(\\beta\\) parameter controls the influence of the Bayesian strength adjustment. Higher values of \\(\\beta\\) more aggressively regress the strength of the team towards the average. </p>"},{"location":"parameters/#h-score-parameters","title":"H-score parameters","text":"<p>The H-score parameters are inputs to the H-scoring procedure. They control the degree to which the algorithm is incentivized to punt, and how long the algorithm runs for. See the documentation on H-scoring for more information. </p>"},{"location":"parameters/#trade-parameters","title":"Trade parameters","text":"<p>The trade parameters limit which potential trades are considered for suggestions. See the section on trade suggestions for the implications of these parameters.</p>"},{"location":"parameters/#position-requirements","title":"Position requirements","text":"<p>H-scoring assumes that either a team conforms to a flexible-enough position structure, or it is invalid. The exact position structure that it checks against is configurable by the user.</p> <p></p> <p>Flex slots like Utilities and Guards can be filled by players of multiple different positions. Bench slots are filled by the last players drafted, and do not count for the H-scoring calculations. </p> <p>It is important to note that this position structure should not necessarily be the same as the league's position structure. The league position structure might include bench slots which players can be moved in and out of on a day-to-day basis to make their games count. Players sitting on that kind of bench do matter, so long as the team is balanced enough in terms of position to accomodate all the players who are active on a given day. Those bench slots should be included as Utilities, or perhaps extra Guards or Forwards to ensure adequate balance. The proper configuration will depend on the rules of a league and some degree of personal preference. </p>"},{"location":"projectionadjustment/","title":"Adjusting the projections with a Bayesian prior","text":"<p>H-scoring as described by the papers is fully reliant on a single set of projections. If a drafter takes a player it projects to be a poor performer highly, the algorithm will not \"doubt itself\" and consider the possibility that its projections for that player are too low. It will assume that pick was a poor choice and the drafter who took it will have a bad team. </p> <p>This inability to doubt itself makes the algorithm overconfident, believing that its own team is very strong, when its own projections are not necessarily better than those implicitly used by other drafters. As a practical matter this can lead the algorithm to think its team is so strong that the only way to improve is to \"un-punt\" categories it has given up on, which is probably a bad idea in practice. </p> <p>The papers assume that player projections are all known and agreed upon by all the drafters, so they don't address this issue. However, it is so important in practice that I've added a module specifically to address it. </p>"},{"location":"projectionadjustment/#the-adjustment","title":"The adjustment","text":"<p>An adjustment is made to the algorithm's assessment of its team's strength for any pick after the first. </p> <p>Say that \\(w\\) is a vector of the algorithm's naive guess at how likely it is to win each category, before performing gradient descent to optimize a future strategy. Corrected versions are calculated as</p> \\[ w^* = \\left[ I_{n \\times n} + \\frac{\\beth}{ n^2}\\mathbf{1}_{n \\times n}  \\right]^{-1} \\left[ w + \\frac{\\beth}{2n} \\mathbf{1}_n \\right ] \\] <p>Where \\(n\\) is the number of categories and \\(\\beth\\) is a parameter. The intuition on what this expression is doing is not immediately clear, but some intuition can be gleaned from the justification in the following section. </p> <p>These corrected win rates are then used to reverse engineer an adjusted expectation of the team's current strength, like so: </p> \\[ x^* = \\text{CDF}^{-1} \\left( w^* \\right) \\] <p>This way, as the punting strategy changes, the algorithm's opinion of its own team does not change. Re-adjusting the win rates every for every iteration of the algorithm based on the current expected win rates would implicitly change the algorithm's opinion of its pre-existing team based on its strategy for the future, which does not make much sense. </p>"},{"location":"projectionadjustment/#justification","title":"Justification","text":"<p>Say that we have prior expectations that </p> <ul> <li>Our average win rate across all categories is approximately 50%, with Normally distributed error. </li> <li>Our guesses for how often we will win a category are unbiased, but have some Normally distributed error. </li> </ul> <p>This information provides a Bayesian framework for re-calculating adjusted category-level win rates. </p> <p>By Bayes' rule, the probability of a certain set of category win rates being correct is proportional to its likelihood time the prior. In this case, the likelihood is </p> \\[ \\prod_c \\phi (\\frac{w^*_c - w_c}{\\epsilon_a}) \\] <p>And the prior probability is </p> \\[ \\phi \\left( \\frac{\\frac{ \\sum_c \\left( w^*_c - \\frac{1}{2} \\right)}{n}}{\\epsilon_b} \\right) =  \\phi \\left( \\frac{ \\sum_c \\left( w^*_c - \\frac{1}{2} \\right)}{\\epsilon_b n} \\right) \\] <p>Multiplying them together yeilds </p> \\[ \\left[ \\prod_c \\phi \\left(\\frac{w^*_c - w_c}{\\epsilon_a} \\right) \\right] \\left[ \\phi \\left(\\frac{ \\sum_c \\left( w^*_c - \\frac{1}{2} \\right)}{\\epsilon_b n } \\right) \\right] \\] <p>We are only interested in what has the maximal likelihood, not what that likelihood is. So it is fine to convert this to log odds, which are </p> \\[ \\left[ \\sum_c \\left(\\frac{w^*_c - w_c}{\\epsilon_a} \\right)^2 \\right] +  \\left(\\frac{ \\sum_c \\left( w^*_c - \\frac{1}{2} \\right)}{\\epsilon_b n} \\right)^2  \\] <p>To optimize this, we set the derivative to zero. Applying the chain rule for category d- </p> \\[ 0 = 2 \\left(\\frac{w^*_d - w_d}{\\epsilon_a} \\right) \\frac{1}{\\epsilon_a} + 2 \\left(\\frac{ \\sum_c \\left( w^*_c - \\frac{1}{2} \\right)}{\\epsilon_b n} \\right) \\frac{1}{\\epsilon_b n} \\] <p>Isolating \\(w^*_d\\)- </p> \\[ 2 \\left(\\frac{w_d}{\\epsilon_a^2} \\right) - 2 \\left(\\frac{ \\sum_{c \\neq d}  \\left( w^*_c \\right) - \\frac{n}{2}}{\\epsilon_b n} \\right) \\frac{1}{\\epsilon_b n}= 2 \\left(\\frac{w^*_d}{\\epsilon_a} \\right) \\frac{1}{\\epsilon_a} + 2 \\frac{w^*_d}{\\epsilon_b^2 n^2} \\] \\[ 2 \\left(\\frac{w_d}{\\epsilon_a^2} \\right) - 2 \\left(\\frac{ \\sum_{c \\neq d}  \\left( w^*_c \\right) - \\frac{n}{2}}{\\epsilon_b n} \\right) \\frac{1}{\\epsilon_b n}= w^*_d \\left( 2 \\frac{1}{\\epsilon_a^2} + 2 \\frac{1}{\\epsilon_b^2 n^2} \\right)  \\] <p>So </p> \\[ w^*_d = \\frac{\\frac{w_d}{\\epsilon_a^2} - \\left(\\frac{ \\sum_{c \\neq d}  \\left( w^*_c \\right) - \\frac{n}{2}}{\\epsilon_b^2 n^2} \\right) }{\\frac{1}{\\epsilon_a^2} + \\frac{1}{\\epsilon_b^2 n^2}} \\] <p>With \\(\\beth = \\frac{\\epsilon_a^2}{\\epsilon_b^2}\\), this is </p> \\[ w^*_d = \\frac{w_d - \\beth \\left(\\frac{ \\sum_{c \\neq d}  \\left( w^*_c \\right) - \\frac{n}{2}}{ n^2} \\right) }{1 + \\frac{\\beth}{ n^2}} \\] <p>This expression is the best for gleaning intution behind the adjustment. When the average win rate is high, a larger quantity is subtracted out from all the win rates. If the win rates are all 50%, the numerator becomes \\(\\frac{1}{2} + \\frac{\\beth}{2n}\\), cancelling with the denominator and keeping win rates constant. Higher values of \\(\\beth\\) increase the importance of the distortion term and decrease the importance of the original win rate.</p> <p>While being relatively interpretable, this expression unfortunately cannot be used directly because all of the \\(w^*_c\\) values are unknowns. Some linear algebra is required with the vector forms of \\(w\\) and \\(w^*\\). </p> <p>With \\(J\\) as matrix with \\(0\\) on all diagonals and \\(1\\) on all non-diagonals, the equation can be written </p> \\[ w^* = \\frac{w - \\frac{\\beth J_{n \\times n} w^*}{n^2} + \\frac{\\beth}{2n}\\mathbf{1}_n }{\\left( 1 + \\frac{\\beth}{ n^2} \\right)} \\] <p>Or </p> \\[ \\left( 1 + \\frac{\\beth}{ n^2}\\right) I_{n \\times n} w^* = w - \\frac{\\beth J_{n \\times n} w^*}{n^2} + \\frac{\\beth}{2n} \\mathbf{1}_n \\] <p>Isolating \\(w^*\\) yields </p> \\[ \\left[ \\left( 1 + \\frac{\\beth}{ n^2}\\right) I_{n \\times n} + \\frac{\\beth}{ n^2}  J_{n \\times n} \\right] w^* = w + \\frac{\\beth}{2n} \\mathbf{1}_n \\] <p>The \\(J\\) can be simplified out </p> \\[ \\left[ I_{n \\times n} + \\frac{\\beth}{ n^2}\\mathbf{1}_{n \\times n}  \\right] w^* = w + \\frac{\\beth}{2n} \\mathbf{1}_n \\] <p>Finally, the matrix can be inverted to yield an expression for \\(w^*\\)</p> \\[ w^* = \\left[ I_{n \\times n} + \\frac{\\beth}{ n^2}\\mathbf{1}_{n \\times n}  \\right]^{-1} \\left[ w + \\frac{\\beth}{2n} \\mathbf{1}_n \\right ] \\]"},{"location":"roto/","title":"Rotisserie","text":"<p>The Rotisserie format is significantly different from the two Head-to-Head formats, necessitating some adaptations.</p>"},{"location":"roto/#variance-in-player-performances","title":"Variance in player performances","text":"<p>Variance in player performances is a key input to the G-score calculation. That means week-to-week variance in the case of Head-to-Head, and uncertainty in season-long performance in the case of Rotisserie. The same quantity is also relevant to H-scoring. While week-to-week variance is relatively simple to estimate based on historical data, pre-season uncertainty is harder to quantify and not studied thoroughly. That creates an issue for using G-scores for Rotisserie in practice.</p> <p>The website's way of handling this is to use scaled week-to-week variance as a proxy for seasonal uncertainty. The \u03c7 factor, which defaults to 60%, controls the degree of scaling. It is one of the input parameters.</p> <p>More technically: the assumption is that the variance over the ~20 weeks in a season will be \u03c7 times the week-to-week variance times 20. If week-to-week variance was the only source of variance, \u03c7 would be effectively 22%. It is likely higher than that before the season, because there is uncertainty about rotations, playing time, offseason improvements, etc. 60% is an estimate with essentially no justification, it can be changed as desired. </p>"},{"location":"roto/#adapting-h-scores","title":"Adapting H-scores","text":"<p>The H-scoring algorithm for Rotisserie is described in the third paper. It considers each categorical matchup as a potential fantasy point, because ultimately with Rotisserie scoring every opponent beaten in a category translates to a fantasy point. It then aggregates those individual fantasy points into a distribution of total fantasy points. That distribution is combined with expectations for other teams' fantasy points to calculate the probability that the drafter will end up the highest total. </p> <p>Because Rotisserie is based on fantasy point totals instead of individual match-up victory probabilities, the H-score display for Rotisserie shows expected category totals instead of average matchup winning probabilities. </p> <p></p> <p>Top Rotisserie H-scores, for the 2024-25 season</p> <p>There are a few things to note about this display. </p> <p>One is that since overall H-scores in the Rotisserie context are the probability of winning an entire league rather than a single matchup, they tend to be much lower. The average is around 8% instead of 50%. </p> <p>Another is that adding up the number of expected fantasy points will lead to a total that appears underwhelming, and unlikely to be enough to win any league. That is because the average outcome is almost always going to be far from enough to actually win. The algorithm is banking on some degree of good luck to have any chance of winning, and that is not reflected in the expected values. </p>"},{"location":"roto/#general-strategy","title":"General strategy","text":"<p>It is conventional wisdom that punting is a bad idea in Rotisserie, because winning the entire league essentially requires strong performance in every category. The H-scoring algorithm for Rotisserie largely bears this out, only ever punting Free Throw % for which some players are extreme negative outliers. </p> <p></p> <p>Image from the paper. \u03c7 set to 50%</p> <p>For the most part, the algorithm aims to be moderately strong in all categories. It does tend to deprioritize volatile categories like Turnovers, though only slightly. It wants to win them, it is just banking on some degree of luck to win those categories, instead of investing heavily in them. It chooses to bank on luck in those categories because they are more volatile than the others, and therefore a small amount of luck will go a longer way.</p>"},{"location":"season/","title":"Season Mode","text":""},{"location":"season/#waiver-wire-free-agents-tab","title":"Waiver wire &amp; free agents tab","text":"<p>The waiver wire tab evaluates whether an available player might fit better on an existing team than one of the players already on the team.</p> <p></p> <p>Substitution H-scores for a synthetic team with Derrick Jones Jr. on it, based on the 2024-25 season</p> <p>The player who is a candidate to be dropped is removed from the team, and H-scores are calculated for all available players plus the drop candidate. The drop candidate is highlighted in blue. Players who do not fit the position structure of the team are filtered out and their H-scores are not shown. </p> <p>These H-scores are relatively simple to calculate, because all other players are known and there is no need to strategize around future draft picks. For that reason, the algorithm does not iterate at all and results are shown immediately. The H-score details tab would not be relevant and is not provided. </p> <p>A corresponding view is available for G-scores. </p> <p></p> <p>G-scores for available players compared to Derrick Jones Jr., based on the 2024-25 season</p> <p>The G-scores shown are the scores of the individual players, not what the scores would be for the team if that player was added. </p>"},{"location":"season/#trading-tab","title":"Trading tab","text":"<p>The trading tab analyzes the H-score and G-score implications of potential trades. It also provides recommendations for trades. </p>"},{"location":"season/#trade-analysis","title":"Trade analysis","text":"<p>The trade analysis module analyzes trades proposed by the user. </p> <p></p> <p>The thumbs on the H-score tab for 'Your Team' and 'Their Team' indicate whether a trade improves a team's H-score or not. Thumbs up means the trade is beneficial, thumbs down means the trade is not beneficial. This can also be seen by whether the H-score is higher before or after the trade. </p> <p>Trades in which the same number of players is sent and received are relatively simple to analyze. First, players are switched, then both teams are checked for position structure. If either team is ineligible, then no results will be shown. Otherwise, H-scores are recomputed and compared against the previous H-scores. </p> <p>Asymmetrical trades can also be analyzed, though the methodology is more complicated and less reliable. The post-trade team that goes down in number of players is scored with the normal H-scoring algorithm, which chooses one candidate from the pool of available players and generates a future draft strategy if needed. The post-trade team that goes up in players is scored by checking every possible set of players that could be dropped and finding the option that maximizes H-score. The players chosen for addition/removal through these calculations are not shown. </p> <p>Because a player gets added during an asymmetrical trade, it is important for asymmetrical trade analysis that the list of available players is accurate. A valuable player that appears to be on the waiver wire will artificially make any trade that goes down in players look beneficial, because it allows for that player to be added. Another consideration is that highly assymetrical trades can take time to process because every possible combination of players to be dropped is being analyzed. </p> <p>A G-score table is also provided, which shows the net changes in G-scores for both teams by category.</p> <p></p> <p>This view is available even if the trade is impermissible by position structure. </p>"},{"location":"season/#trade-suggestions","title":"Trade suggestions","text":"<p>Below the trade analysis module, trade suggestions are shown. </p> <p></p> <p>Which trades end up being shown as suggestions depends on the user-configurable trade parameters. </p> <p>Candidate trades are found by first heuristically estimating which players might be more favored by the other team, then iterating through all combinations of possible trades with those players. Those trades are further filtered by a general value difference threshold, which is based on user inputs.</p> <p></p> <p>The general value thresholds limit candidate trades to those between collections of players whose total general values are similar to each other. If the absolute value of the difference in total general value between the two groups of players that are to be traded is above the threshold, the trade will not be considered for analysis. This is to prevent unnecessary computation checking trades that are unlikely to be viable. </p> <p>General value is defined by base H-score (the H-scores the players would have for the first pick of the draft), as a percent. So if the general value threshold is 10, a total base H-score difference of 10% between players is allowed. For asymmetrical trades, the general value of an empty slot is the replacement-level base H-score. </p> <p>Thresholds should generally be lower for trade configurations with larger numbers of players involved, because those require checking many more combinations of players. Decreasing the limit and excluding more potential trades limits computation time. </p> <p>Trade suggestions can be generated for any kind of trade for which a general strength difference threshold is provided. By default 1x1, 2x2, and 3x3 trades are included, and users can add more through the trade parameters popover. </p> <p>After trades are analyzed for H-score implications, one more filter is applied. Only those which meet the H-score differential thresholds as supplied by the user are shown. </p> <p></p> <p>The thresholds are in terms of H-score as a percentage, so if the threshold for a party is -0.2, then trades that decrease the party's H-score by more than 0.2% are not shown. </p> <p>Even with all this filtering, there can be many possible trades to look through, especially when looking for trades with large numbers of players and when the parameters for acceptable trades are loose. For the purpose of limiting computation time, only 1x1 trades are searched for by default. </p>"},{"location":"season/#rosters-tab","title":"Rosters tab","text":""},{"location":"season/#roster-table","title":"Roster table","text":"<p>Rosters can be manually input or edited on this tab. It is unneccesary if rosters are loaded through a platform integration.</p> <p></p> <p>Information from the roster table will only flow through to other components after the 'Lock in' button is pressed. This is to prevent the website from continually updating itself while many players are being added at the same time. </p> <p>Only players from the loaded dataset can be added to the roster table, which are shown on a searchable drop-down for each cell. The same player can be added multiple times.</p> <p></p> <p>Nikola Jokic is still shown as an option after already being taken by another team</p> <p>Generally draft results can be copy-pasted from the drafting view into an Excel and then into this table, so long as the dataset of valid players remains the same. Occasionally there are bugs with copy-pasting into the rosters table, such as the first column not being copied over. In that case, the few remaining players can be entered by hand. </p>"},{"location":"season/#roster-inspection","title":"Roster inspection","text":"<p>Individual teams can be analyzed in terms of G-score. H-scores are not provided in this view. </p>"},{"location":"settings/","title":"Settings","text":"<p>Settings are available for live connections to fantasy providers, customizable projection uploads, and adapting to different kinds of scoring. They are accessible via the left sidebar.</p>"},{"location":"settings/#league-settings","title":"League settings","text":""},{"location":"settings/#fantasy-sport","title":"Fantasy sport","text":"<p>For now, this will just be NBA. MLB or WNBA may be added in the future</p>"},{"location":"settings/#data-integration","title":"Data integration","text":"<p>The default option for getting data on drafting situation/teams is entering it manually. </p> <p>There is also an option for integrating with a fantasy provider, which allows the website to be used with real fantasy occuring on those platforms. The website will show analysis based on the integrated league. It will never make a pick or take any action itself. </p> <p>The three platforms currently supported are: </p> <p>Yahoo: support exists both for pulling existing teams during the season, and for integrating with drafts. This includes mock drafts. To integrate, one must authenticate with Yahoo by following the link on the pop-up generated when Yahoo is selected.</p> <p></p> <p>Once the connection is established, relevant leagues will show up, if any. Mock drafts can also be connected to via manually copy-pasting the code for the mock draft.</p> <p>FYI there is a bug in the wrapper used for connecting to the Yahoo API, which crashes the app when a drafter has a name that is a pure number. </p> <p></p> <p>Fantrax: support exists both for pulling existing teams during the season, and for integrating with drafts. However this only works with public drafts. </p> <p></p> <p>ESPN: support only exists for pulling existing teams during the season. Unfortunately, ESPN has no API for draft access. To authenticate to pull a team, a web plug-in is needed. The instructions are on the pop-up generated when ESPN is selected. </p> <p></p>"},{"location":"settings/#mode","title":"Mode","text":"<p>There are three available modes. </p> <p>Draft mode: for standard drafts. When drafted players are input manually, only snake drafts are naturally supported. If the drafted players are being pulled via an integration, the website will continually evaluate the best prospects regardless of draft position, so any drafting order will work fine. </p> <p>Auction mode: for auction drafts. Users must specify that they are doing an auction for either manual entry or platform integration.</p> <p>Season mode: for leagues where teams have already been built. Season mode allows for the inspection of potential free agents, and also includes a trading module. </p>"},{"location":"settings/#other-info","title":"Other info","text":"<p>If draft data is being input manually, the number of drafters, the number of picks per drafter, and the team names of the drafters are also inputs. </p>"},{"location":"settings/#player-statistics","title":"Player statistics","text":"<p>Player statistics are an input to the algorithms implemented by the website. They can be sourced either from forward-looking projections or previous NBA seasons.</p>"},{"location":"settings/#projection","title":"Projection","text":"<p>The default for player statistics is to use forward-looking projections. </p> <p></p> <p>The default projection source is a 50/50 split between ESPN's free forecasts and a modified version of DARKO. The website's version of DARKO projections takes games played and total minutes from the ESPN forecasts, and combines those with DARKO pace and per-possession projections to get per-game projections. This is necessary because DARKO does not forecast games played, and its minute forecasts are designed for the next game only, which is not ideal for fantasy. </p> <p>Two additional kinds of forecasts are also available: those created by Hashtag Basketball, and Basketball Monster (BBM). Both of these projections are paid products, so they cannot be provided through the website. Instead, they must be purchased and uploaded. For HTB, there is no native download option for projections. The projections must be copy pasted into an Excel file and saved as a CSV. For BBM, there is a download option, but only the XLSX download option works. Download it, copy out the projections into Excel, and save them as a CSV UTF-8. Either kind of projection can be manually edited to change projections if desired. </p> <p>Also: be careful to download projections for all players instead of just the top players. During a draft, another drafter may take a player outside of the limited projection list, and the website will only have projections for them if they have been provided. </p> <p>Projections are combined between different sources by taking weighted means according to the provided weights. If the assigned weights add up to more or less than 1, they will be scaled to add to 1. </p>"},{"location":"settings/#historical","title":"Historical","text":"<p>Historical data is available for manual entry drafts. </p> <p></p> <p>Historical data is available going all the way back to the 1984-85 season, though for any season before 2000-01 player positions will not be available. </p> <p></p> <p>H-scores for the 1984-85 season, Each Category. NP means no position</p> <p>Historical data cannot be used when integrated with a fantasy platform, because platforms do not run leagues based on past seasons.  </p>"},{"location":"settings/#formats-categories","title":"Formats &amp; categories","text":"<p>The website supports the three common category formats for fantasy basketball: H2H Each Category, H2H Most Categories, and Rotisserie. It does not have native support any additional variants, like using a specific category as a tiebreaker. </p> <p>It also supports any combination of categories, across the default nine categories and several alternative options.</p> <p></p> <p>For the alternative categories, when using projections, make sure to include them when sourcing the projections. ESPN and DARKO do not forecast them so all of the weight will be from Hashtag or BBM projections. </p>"}]}